{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 yong_chen 3360\n",
      "#papers  3253\n",
      "#authors 5904\n",
      "#org_words 1307\n",
      "#confs   1337\n",
      "walks done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dh/miniconda3/envs/dhbase/lib/python3.6/site-packages/ipykernel_launcher.py:69: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/home/dh/miniconda3/envs/dhbase/lib/python3.6/site-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "walks done\n",
      "relational outlier: {3202, 3205, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2439, 2064, 2065, 2450, 3211, 3221, 535, 536, 537, 3224, 540, 541, 542, 544, 545, 546, 547, 548, 549, 933, 551, 552, 553, 935, 937, 938, 3207, 3275, 1747, 1748, 1749, 1750, 1751, 1244, 3178, 3187, 3198}\n",
      "semantic outlier: set()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.models import word2vec\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from utils import *\n",
    "\n",
    "pubs_raw = load_json(\"train\",\"train_pub.json\")\n",
    "name_pubs = load_json(\"train\",\"train_author.json\")\n",
    "\n",
    "result=[]\n",
    "for n,name in enumerate(name_pubs):\n",
    "    ilabel=0\n",
    "    pubs=[] # all papers\n",
    "    labels=[] # ground truth\n",
    "    \n",
    "    # {\n",
    "    #     authorID1 : [pubid1,pubid2,...],\n",
    "    #     authorID2 : [pubid2,pubid6,...],\n",
    "    #     ...\n",
    "    # }\n",
    "    for author in name_pubs[name]:\n",
    "        iauthor_pubs = name_pubs[name][author]\n",
    "        for pub in iauthor_pubs:\n",
    "            pubs.append(pub)\n",
    "            labels.append(ilabel)\n",
    "        ilabel += 1\n",
    "    # pubs存储了当前名字下所有的论文\n",
    "    # labels存储了pubs中论文对应作者的label\n",
    "    print (n,name,len(pubs))\n",
    "    \n",
    "    \n",
    "    if len(pubs)==0:\n",
    "        result.append(0)\n",
    "        continue\n",
    "    \n",
    "    ##保存关系\n",
    "    ###############################################################\n",
    "    name_pubs_raw = {}\n",
    "    # pubs存储了当前名字下所有的论文\n",
    "    for i,pid in enumerate(pubs):\n",
    "        name_pubs_raw[pid] = pubs_raw[pid]\n",
    "        # name_pubs_raw={pid:pid_detail}\n",
    "    dump_json(name_pubs_raw, 'genename', name+'.json', indent=4)\n",
    "    save_relation(name+'.json', name)  \n",
    "    ###############################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##元路径游走类\n",
    "    ###############################################################r\n",
    "    mpg = MetaPathGenerator()\n",
    "    mpg.read_data(\"gene\")\n",
    "    ###############################################################\n",
    "    \n",
    "  \n",
    "    \n",
    "    ##论文关系表征向量\n",
    "    ############################################################### \n",
    "    all_embs=[]\n",
    "    rw_num =10\n",
    "    cp=set()\n",
    "    for k in range(rw_num):\n",
    "        mpg.generate_WMRW(\"gene/RW.txt\",3,30) #生成路径集\n",
    "        sentences = word2vec.Text8Corpus(r'gene/RW.txt')\n",
    "        model = word2vec.Word2Vec(sentences, size=100,negative =20, min_count=1, window=10)\n",
    "        embs=[]\n",
    "        for i,pid in enumerate(pubs):\n",
    "            if pid in model:\n",
    "                embs.append(model[pid])\n",
    "            else:\n",
    "                cp.add(i)\n",
    "                embs.append(np.zeros(100))\n",
    "        all_embs.append(embs)\n",
    "    all_embs= np.array(all_embs)\n",
    "    print ('relational outlier:',cp)\n",
    "    ############################################################### \n",
    "\n",
    "    \n",
    "    \n",
    "    ##论文文本表征向量\n",
    "    ###############################################################   \n",
    "    ptext_emb=load_data('gene','ptext_emb.pkl')\n",
    "    tcp=load_data('gene','tcp.pkl')\n",
    "    print ('semantic outlier:',tcp)\n",
    "    tembs=[]\n",
    "    for pid in pubs:\n",
    "        tembs.append(ptext_emb[pid])\n",
    "    ############################################################### \n",
    "    \n",
    "    ##离散点\n",
    "    outlier=set()\n",
    "    for i in cp:\n",
    "        outlier.add(i)\n",
    "    for i in tcp:\n",
    "        outlier.add(i)\n",
    "    \n",
    "    ##网络嵌入向量相似度\n",
    "    sk_sim = np.zeros((len(pubs),len(pubs)))\n",
    "    for k in range(rw_num):\n",
    "        sk_sim = sk_sim + pairwise_distances(all_embs[k],metric=\"cosine\")\n",
    "    sk_sim =sk_sim/rw_num \n",
    "\n",
    "    \n",
    "    ##文本相似度\n",
    "    t_sim = pairwise_distances(tembs,metric=\"cosine\")\n",
    "    \n",
    "    # 加权求整体相似度\n",
    "    w=0.5\n",
    "    sim = (np.array(sk_sim) + w*np.array(t_sim))/(1+w)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##evaluate\n",
    "    ###############################################################\n",
    "    pre = DBSCAN(eps = 0.15, min_samples = 3,metric =\"precomputed\").fit_predict(sim)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    for i in range(len(pre)):\n",
    "        if pre[i]==-1:\n",
    "            outlier.add(i)\n",
    "    \n",
    "    ## assign each outlier a label\n",
    "    paper_pair = generate_pair(pubs,outlier)\n",
    "    paper_pair1 = paper_pair.copy()\n",
    "    K = len(set(pre))\n",
    "    for i in range(len(pre)):\n",
    "        if i not in outlier:\n",
    "            continue\n",
    "        j = np.argmax(paper_pair[i])\n",
    "        while j in outlier:\n",
    "            paper_pair[i][j]=-1\n",
    "            j = np.argmax(paper_pair[i])\n",
    "        if paper_pair[i][j]>=1.5:\n",
    "            pre[i]=pre[j]\n",
    "        else:\n",
    "            pre[i]=K\n",
    "            K=K+1\n",
    "    \n",
    "    ## find nodes in outlier is the same label or not\n",
    "    for ii,i in enumerate(outlier):\n",
    "        for jj,j in enumerate(outlier):\n",
    "            if jj<=ii:\n",
    "                continue\n",
    "            else:\n",
    "                if paper_pair1[i][j]>=1.5:\n",
    "                    pre[j]=pre[i]\n",
    "            \n",
    "            \n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    pre = np.array(pre)\n",
    "    print (labels,len(set(labels)))\n",
    "    print (pre,len(set(pre)))\n",
    "    pairwise_precision, pairwise_recall, pairwise_f1 = pairwise_evaluate(labels,pre)\n",
    "    print (pairwise_precision, pairwise_recall, pairwise_f1)\n",
    "    result.append(pairwise_f1)\n",
    "\n",
    "    print ('avg_f1:', np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3360"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
